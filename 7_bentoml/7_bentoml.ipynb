{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05d0c727",
   "metadata": {},
   "source": [
    "# 7. Production-Ready Machine Learning (Bento ML)\n",
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e17ec",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "You are a new recruit at ACME corp. Your manager is emailing you about your first assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d9a76",
   "metadata": {},
   "source": [
    "### Email from your manager\n",
    "\n",
    "Good morning recruit! It's good to have you here! I have an assignment for you. I have a data scientist that's built\n",
    "a credit risk model in a jupyter notebook. I need you to run the notebook and save the model with BentoML and see\n",
    "how big the model is. If it's greater than a certain size, I'm going to have to request additional resources from \n",
    "our infra team. Please let me know how big it is.\n",
    "\n",
    "Thanks,\n",
    "\n",
    "Mr McManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8183b",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "* Install BentoML\n",
    "* What's the version of BentoML you installed?\n",
    "* Use `--version` to find out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197c289",
   "metadata": {},
   "source": [
    "### Solution steps:\n",
    "\n",
    "Enter in Terminal:\n",
    "\n",
    "```bash\n",
    "install bentoml\n",
    "```\n",
    "```bash\n",
    "bentoml --version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f46c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bentoml, version 1.0.7.post41+gac8e68b\r\n"
     ]
    }
   ],
   "source": [
    "! bentoml --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a888c97f",
   "metadata": {},
   "source": [
    "**Answer 1:** The version of installed BentoML is **1.0.7**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6f9b49",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Run the notebook which contains the xgboost model from module 6 i.e previous module and save the xgboost model with BentoML. To make it easier for you we have prepared this [notebook](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/07-bentoml-production/code/train.ipynb).\n",
    "\n",
    "How big approximately is the saved BentoML model? Size can slightly vary depending on your local development environment.\n",
    "Choose the size closest to your model.\n",
    "\n",
    "* 924kb\n",
    "* 724kb\n",
    "* 114kb\n",
    "* 8kb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706ae9f",
   "metadata": {},
   "source": [
    "### Solution steps:\n",
    "\n",
    "We follow the [Tutorial: Intro to BentoML](https://docs.bentoml.org/en/latest/tutorial.html).\n",
    "\n",
    "\n",
    "The model is built and trained in the notebook [train.ipynb](./train.ipynb).\n",
    "\n",
    "We run the notebook, the model is saved with BentoML API in its model store (a local directory managed by BentoML).\n",
    "\n",
    "Enter in Terminal:\n",
    "\n",
    "```bash\n",
    "bentoml models list\n",
    "```\n",
    "\n",
    "We can see information about saved models. The size is 116.25 KiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637a3dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\r\n",
      " credit_risk_model:zssgr7cr6…  bentoml.xgboost  116.25 KiB  2022-10-22 13:17:57 \r\n"
     ]
    }
   ],
   "source": [
    "! bentoml models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce33a3d4",
   "metadata": {},
   "source": [
    "**Answer 2:** The size of the saved BentoML model is **114kb**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae436c",
   "metadata": {},
   "source": [
    "## Another email from your manager\n",
    "\n",
    "Great job recruit! Looks like I won't be having to go back to the procurement team. Thanks for the information.\n",
    "\n",
    "However, I just got word from one of the teams that's using one of our ML services and they're saying our service is \"broken\"\n",
    "and their trying to blame our model. I looked at the data their sending and it's completely bogus. I don't want them\n",
    "to send bad data to us and blame us for our models. Could you write a pydantic schema for the data that they should be sending?\n",
    "That way next time it will tell them it's their data that's bad and not our model.\n",
    "\n",
    "Thanks,\n",
    "\n",
    "Mr McManager\n",
    "\n",
    "## Question 3\n",
    "\n",
    "Say you have the following data that you're sending to your service:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"name\": \"Tim\",\n",
    "  \"age\": 37,\n",
    "  \"country\": \"US\",\n",
    "  \"rating\": 3.14\n",
    "}\n",
    "```\n",
    "\n",
    "What would the pydantic class look like? You can name the class `UserProfile`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e621f7b",
   "metadata": {},
   "source": [
    "### Solution steps:\n",
    "\n",
    "Enter in Terminal:    \n",
    "```bash\n",
    "pip3 install pydantic\n",
    "```\n",
    "\n",
    "Then in ```service.py``` add lines:\n",
    "\n",
    "```from pydantic import BaseModel```\n",
    "\n",
    "```class UserProfile(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    country: str\n",
    "    rating: float```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545957fa",
   "metadata": {},
   "source": [
    "**Answer 3:** \n",
    "```class UserProfile(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    country: str\n",
    "    rating: float``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59419e1a",
   "metadata": {},
   "source": [
    "## Email from your CEO\n",
    "\n",
    "Good morning! I hear you're the one to go to if I need something done well! We've got a new model that a big client\n",
    "needs deployed ASAP. I need you to build a service with it and test it against the old model and make sure that it performs\n",
    "better, otherwise we're going to lose this client. All our hopes are with you!\n",
    "\n",
    "Thanks,\n",
    "\n",
    "CEO of Acme Corp\n",
    "\n",
    "## Question 4\n",
    "\n",
    "We've prepared a model for you that you can import using:\n",
    "\n",
    "```bash\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel.bentomodel\n",
    "bentoml models import coolmodel.bentomodel\n",
    "```\n",
    "\n",
    "What version of scikit-learn was this model trained with?\n",
    "\n",
    "* 1.1.1\n",
    "* 1.1.2\n",
    "* 1.1.3\n",
    "* 1.1.4\n",
    "* 1.1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da73a26",
   "metadata": {},
   "source": [
    "### Solution steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59c6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1724  100  1724    0     0   1267      0  0:00:01  0:00:01 --:--:--  1268\n"
     ]
    }
   ],
   "source": [
    "# download a model with the command:\n",
    "!curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel.bentomodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba268ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(tag=\"mlzoomcamp_homework:qtzdz3slg6mwwdu5\") imported.\r\n"
     ]
    }
   ],
   "source": [
    "# now import the model:\n",
    "!bentoml models import coolmodel.bentomodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff828056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\r\n",
      " credit_risk_model:zssgr7cr6…  bentoml.xgboost  116.25 KiB  2022-10-22 13:17:57 \r\n",
      " mlzoomcamp_homework:qtzdz3s…  bentoml.sklearn  5.79 KiB    2022-10-13 23:42:14 \r\n"
     ]
    }
   ],
   "source": [
    "# to see information about saved model enter in Terminal (without !-sign):\n",
    "!bentoml models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271ac75",
   "metadata": {},
   "source": [
    "Then we can copy the name and version pair of the latest saved model: \n",
    "```mlzoomcamp_homework:qtzdz3slg6mwwdu5```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a4de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91;40mname\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mmlzoomcamp_homework\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[91;40mversion\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mqtzdz3slg6mwwdu5\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[91;40mmodule\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mbentoml.sklearn\u001b[0m\u001b[40m                                                         \u001b[0m\r\n",
      "\u001b[91;40mlabels\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                      \u001b[0m\r\n",
      "\u001b[91;40moptions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                     \u001b[0m\r\n",
      "\u001b[91;40mmetadata\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m{\u001b[0m\u001b[40m}\u001b[0m\u001b[40m                                                                    \u001b[0m\r\n",
      "\u001b[91;40mcontext\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                        \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_name\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40msklearn\u001b[0m\u001b[40m                                                       \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mframework_versions\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                           \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[91;40mscikit-learn\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.1.1\u001b[0m\u001b[40m                                                         \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mbentoml_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m1.0.7\u001b[0m\u001b[40m                                                        \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mpython_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40m3.9.12\u001b[0m\u001b[40m                                                        \u001b[0m\r\n",
      "\u001b[91;40msignatures\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                     \u001b[0m\r\n",
      "\u001b[97;40m  \u001b[0m\u001b[91;40mpredict\u001b[0m\u001b[97;40m:\u001b[0m\u001b[40m                                                                      \u001b[0m\r\n",
      "\u001b[97;40m    \u001b[0m\u001b[91;40mbatchable\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mfalse\u001b[0m\u001b[40m                                                            \u001b[0m\r\n",
      "\u001b[91;40mapi_version\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[40mv1\u001b[0m\u001b[40m                                                                 \u001b[0m\r\n",
      "\u001b[91;40mcreation_time\u001b[0m\u001b[97;40m:\u001b[0m\u001b[97;40m \u001b[0m\u001b[93;40m'\u001b[0m\u001b[93;40m2022-10-13T20:42:14.411084+00:00\u001b[0m\u001b[93;40m'\u001b[0m\u001b[40m                               \u001b[0m\r\n",
      "\u001b[40m                                                                                \u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# to view details of this model:\n",
    "!bentoml models get mlzoomcamp_homework:qtzdz3slg6mwwdu5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbbb0f",
   "metadata": {},
   "source": [
    "**Answer 4:** The model was trained with scikit-learn, version **1.1.1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dff30c",
   "metadata": {},
   "source": [
    "## Question 5 \n",
    "\n",
    "Create a bento out of this scikit-learn model. The output type for this endpoint should be `NumpyNdarray()`\n",
    "\n",
    "Send this array to the Bento:\n",
    "\n",
    "```\n",
    "[[6.4,3.5,4.5,1.2]]\n",
    "```\n",
    "\n",
    "You can use curl or the Swagger UI. What value does it return? \n",
    "\n",
    "* 0\n",
    "* 1\n",
    "* 2\n",
    "* 3\n",
    "\n",
    "(Make sure your environment has Scikit-Learn installed) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3907b",
   "metadata": {},
   "source": [
    "### Solution steps:\n",
    "\n",
    "Let's create a python file [service.py](./service.py). Services are the core components of BentoML, where the serving logic is defined.\n",
    "\n",
    "```\n",
    "import bentoml\n",
    "from bentoml.io import NumpyNdarray\n",
    "\n",
    "model_ref = bentoml.sklearn.get(\"mlzoomcamp_homework:qtzdz3slg6mwwdu5\")\n",
    " \n",
    "model_runner = model_ref.to_runner()\n",
    "\n",
    "svc = bentoml.Service(\"mlzoomcamp_homework\", runners=[model_runner])\n",
    "\n",
    "\n",
    "@svc.api(input=NumpyNdarray(), output=NumpyNdarray())\n",
    "async def classify(vector):\n",
    "    prediction = await model_runner.predict.async_run(vector)\n",
    "    print(prediction)\n",
    "    \n",
    "    return prediction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f53eaec",
   "metadata": {},
   "source": [
    "To run the BentoML server for our new service in development mode in Terminal go inside the folder with ```service.py``` and enter the following command:\n",
    "\n",
    "```bash\n",
    "bentoml serve service.py:svc --reload\n",
    "```\n",
    "\n",
    "Now our service is running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae26af96",
   "metadata": {},
   "source": [
    "Open http://127.0.0.1:3000 in our browser and send prediction request ```[[6.4,3.5,4.5,1.2]]``` from the web UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecded345",
   "metadata": {},
   "source": [
    "Or use the curl-command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcce9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]"
     ]
    }
   ],
   "source": [
    "!curl -X POST -H \"content-type: application/NumpyNdarray\" --data \"[[6.4,3.5,4.5,1.2]]\" http://127.0.0.1:3000/classify\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019aaca",
   "metadata": {},
   "source": [
    "**Answer 5:** **1**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d547b9",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Ensure to serve your bento with `--production` for this question\n",
    "\n",
    "Install locust using:\n",
    "\n",
    "```bash\n",
    "pip install locust\n",
    "```\n",
    "\n",
    "Use the following locust file: [locustfile.py](locustfile.py)\n",
    "\n",
    "Ensure that it is pointed at your bento's endpoint (In case you didn't name your endpoint \"classify\").\n",
    "\n",
    "Configure 100 users with ramp time of 10 users per second. Click \"Start Swarming\" and ensure that it is working.\n",
    "\n",
    "Now download a second model with this command:\n",
    "\n",
    "```bash\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel\n",
    "```\n",
    "\n",
    "Or you can download with this link as well:\n",
    "[https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel](https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel)\n",
    "\n",
    "Now import the model:\n",
    "\n",
    "```bash\n",
    "bentoml models import coolmodel2.bentomodel\n",
    "```\n",
    "\n",
    "Update your bento's runner tag and test with both models. Which model allows more traffic (more throughput) as you ramp up the traffic?\n",
    "\n",
    "**Hint 1**: Remember to turn off and turn on your bento service between changing the model tag. Use Ctl-C to close the service in between trials.\n",
    "\n",
    "**Hint 2**: Increase the number of concurrent users to see which one has higher throughput\n",
    "\n",
    "Which model has better performance at higher volumes?\n",
    "\n",
    "* The first model\n",
    "* The second model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5827b",
   "metadata": {},
   "source": [
    "### Solution steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca02e52",
   "metadata": {},
   "source": [
    "We installed locust using:\n",
    "\n",
    "```bash\n",
    "brew install locust\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625216a",
   "metadata": {},
   "source": [
    "Then we run the BentoServer in production mode using:\n",
    "```bash\n",
    "bentoml serve --production -q --host localhost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50cb17",
   "metadata": {},
   "source": [
    "Then we start the Locust process using command:\n",
    "```bash\n",
    "locust -H http://localhost:3000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b109e9",
   "metadata": {},
   "source": [
    "Open web interface at http://0.0.0.0:8089 in our browser.\n",
    "\n",
    "Configure 100 users with ramp time of 10 users per second.\n",
    "\n",
    "Then 200/50, then 300/50, after that 500/50 and finally 1000/50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51cc42",
   "metadata": {},
   "source": [
    "For model ```mlzoomcamp_homework:qtzdz3slg6mwwdu5``` we got the following performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b2ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64ee105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./locus-stats/Statistics_model1.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"./locus-stats/Statistics_model1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faf5278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./locus-stats/Charts_model1.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"./locus-stats/Charts_model1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7282eae9",
   "metadata": {},
   "source": [
    "Turn off our bento service by pressing Ctl-C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632b239",
   "metadata": {},
   "source": [
    "Let's test the second model.\n",
    "\n",
    "We downloaded the second model with this command in Terminal:\n",
    "\n",
    "```bash\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel2.bentomodel\n",
    "```\n",
    "\n",
    "Then import the model:\n",
    "\n",
    "```bash\n",
    "bentoml models import coolmodel2.bentomodel\n",
    "```\n",
    "\n",
    "Model (tag=\"mlzoomcamp_homework:jsi67fslz6txydu5\") imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927b3767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[0m\u001b[1mTag                         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mModule         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mSize      \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mCreation Time      \u001b[0m\u001b[1m \u001b[0m\r\n",
      " credit_risk_model:zssgr7cr6…  bentoml.xgboost  116.25 KiB  2022-10-22 13:17:57 \r\n",
      " mlzoomcamp_homework:jsi67fs…  bentoml.sklearn  5.82 KiB    2022-10-14 17:48:43 \r\n",
      " mlzoomcamp_homework:qtzdz3s…  bentoml.sklearn  5.79 KiB    2022-10-13 23:42:14 \r\n"
     ]
    }
   ],
   "source": [
    "!bentoml models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cabf3ef",
   "metadata": {},
   "source": [
    "Let's update the bento's runner tag  in the file service.py.\n",
    "\n",
    "```model_ref = bentoml.sklearn.get(\"mlzoomcamp_homework:jsi67fslz6txydu5\")```\n",
    "\n",
    "Then we run the BentoServer in production mode using:\n",
    "```bash\n",
    "bentoml serve --production -q --host localhost\n",
    "```\n",
    "Then we start the Locust process using command:\n",
    "```bash\n",
    "locust -H http://localhost:3000\n",
    "```\n",
    "Open web interface at http://0.0.0.0:8089 in our browser.\n",
    "\n",
    "Configure 100 users with ramp time of 10 users per second.\n",
    "\n",
    "Then 200/50, then 300/50, after that 500/50 and finally 1000/50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1baaa",
   "metadata": {},
   "source": [
    "For model ```mlzoomcamp_homework:jsi67fslz6txydu5``` we got the following performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3d78e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./locus-stats/Statistics_model2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"./locus-stats/Statistics_model2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27af028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./locus-stats/Charts_model2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"./locus-stats/Charts_model2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0193be",
   "metadata": {},
   "source": [
    "**Answer 6:** **The second model** has better performance at higher volumes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
